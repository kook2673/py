# -*- coding: utf-8 -*-
"""
ì „ëµ í”Œë«í¼ìš© íŒŒë¼ë¯¸í„° ìµœì í™”(Optimizer) ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 'strategy_platform.py'ì— ì •ì˜ëœ ë‹¤ì–‘í•œ ì „ëµë“¤ì„ ëŒ€ìƒìœ¼ë¡œ
ì§€ì •ëœ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ëŒ€í•œ ê·¸ë¦¬ë“œ íƒìƒ‰(Grid Search)ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë©€í‹°í”„ë¡œì„¸ì‹±(ë³‘ë ¬ ì²˜ë¦¬)ì„ í™œìš©í•˜ì—¬ ìµœì í™” ì†ë„ í–¥ìƒ.
- í…ŒìŠ¤íŠ¸í•  ì „ëµ(ì˜ˆ: RSI, ë³¼ë¦°ì € ë°´ë“œ)ì„ ì‰½ê²Œ ì„ íƒí•˜ê³  í•´ë‹¹ ì „ëµì˜ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ì§€ì •.
- ì§„í–‰ ìƒí™©ì„ JSON íŒŒì¼ì— ì €ì¥í•˜ì—¬, ìŠ¤í¬ë¦½íŠ¸ê°€ ì¤‘ë‹¨ë˜ë”ë¼ë„ ì´ì–´ì„œ ì‘ì—… ê°€ëŠ¥.
- ìµœì¢… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Excel ë“±ì—ì„œ ì‰½ê²Œ ë¶„ì„.
"""

import os
import json
import glob
import itertools
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing

import pandas as pd

# ìƒˆë¡œ ë§Œë“  ë°±í…ŒìŠ¤íŒ… í”Œë«í¼ì—ì„œ í•„ìš” í•¨ìˆ˜/í´ë˜ìŠ¤ ì„í¬íŠ¸
from strategy_platform import run_backtest, RsiMeanReversion, BollingerBandStrategy, MacdStrategy

# --- ì„¤ì • ë³€ìˆ˜ ---
# ë¡œê·¸ ë° ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
script_dir = os.path.dirname(os.path.abspath(__file__))
LOGS_DIR = os.path.join(script_dir, 'logs')
PROGRESS_FILE = os.path.join(LOGS_DIR, 'Opt_Platform_Progress.json')
RESULTS_CSV = os.path.join(LOGS_DIR, 'Opt_Platform_Results.csv')
REALTIME_LOG = os.path.join(LOGS_DIR, 'Opt_Platform_Realtime.log')

# ë°ì´í„° ê²½ë¡œ (ìˆ˜ì •ë¨)
# ê²½ë¡œ ìˆ˜ì •: binance_test2 í´ë” ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í´ë”ì˜ binance_test í´ë”ë¥¼ ë°”ë¼ë³´ë„ë¡ ë³€ê²½
DATA_DIR = os.path.abspath(os.path.join(script_dir, '..', 'binance_test', 'data', 'BTC_USDT', '1m'))

# ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ê³µìœ  ë°ì´í„° (ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ë¡œë“œí•˜ê¸° ìœ„í•¨)
_SHARED_DF = None


def init_worker():
    """ì›Œì»¤ ì´ˆê¸°í™”: ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ë¡œë“œ"""
    global _SHARED_DF
    try:
        log_realtime("ğŸ“¥ ì›Œì»¤ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # 2025ë…„ 1ì›” ~ 2ì›” ë°ì´í„° ì‚¬ìš© (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ê°„ ë‹¨ì¶•)
        all_files = []
        for month in range(1, 3):
            month_pattern = f'2025-{month:02d}.csv'
            files = glob.glob(os.path.join(DATA_DIR, month_pattern))
            all_files.extend(files)
        
        if not all_files:
            raise RuntimeError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}")
        
        dfs = [pd.read_csv(f, index_col='timestamp', parse_dates=True) for f in sorted(all_files)]
        _SHARED_DF = pd.concat(dfs).sort_index().drop_duplicates()
        log_realtime(f"ğŸ‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(_SHARED_DF):,}ê°œ ë°ì´í„°")
        
    except Exception as e:
        _SHARED_DF = None
        raise RuntimeError(f'ì›Œì»¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}')


def run_single_backtest(params_tuple):
    """ì›Œì»¤ì—ì„œ ì‹¤í–‰ë  ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    strategy_class, strategy_params = params_tuple
    
    if _SHARED_DF is None:
        raise RuntimeError('ê³µìœ  ë°ì´í„°í”„ë ˆì„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = run_backtest(
        df_original=_SHARED_DF,
        strategy_class=strategy_class,
        strategy_params=strategy_params,
        trade_type='long_and_short', # ëª¨ë“  ìµœì í™”ëŠ” ë¡±/ìˆ ì–‘ë°©í–¥ìœ¼ë¡œ ì§„í–‰
        initial_capital=10000,
        fee=0.001,
        leverage=10
    )
    
    # ê²°ê³¼ ìš”ì•½
    # íŒŒë¼ë¯¸í„°ë¥¼ ë¬¸ìì—´ í‚¤ë¡œ ë³€í™˜ (JSON í˜¸í™˜)
    param_key = f"{strategy_class.__name__}_{'_'.join([f'{k}{v}' for k, v in strategy_params.items()])}"
    
    out = {
        'key': param_key,
        'strategy': result['strategy'],
        'total_return_pct': result['total_return_pct'],
        'mdd_pct': result['mdd_pct'],
        'num_trades': result['num_trades'],
        'win_rate_pct': result['win_rate_pct'],
    }
    # íŒŒë¼ë¯¸í„°ë“¤ì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
    out.update(strategy_params)
    return out


def generate_param_grid():
    """ìµœì í™”í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ìƒì„±"""
    
    # --- í…ŒìŠ¤íŠ¸í•  ì „ëµê³¼ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ì—¬ê¸°ì— ì •ì˜ ---

    # 1. RSI ì „ëµ íŒŒë¼ë¯¸í„°
    rsi_params = {
        'rsi_window': [14, 21, 30],
        'oversold_threshold': [20, 25, 30],
        'overbought_threshold': [70, 75, 80]
    }
    rsi_grid = [
        (RsiMeanReversion, dict(zip(rsi_params.keys(), p))) 
        for p in itertools.product(*rsi_params.values())
    ]

    # 2. ë³¼ë¦°ì € ë°´ë“œ ì „ëµ íŒŒë¼ë¯¸í„°
    bb_params = {
        'window': [20, 30],
        'std_dev': [2.0, 2.5]
    }
    bb_grid = [
        (BollingerBandStrategy, dict(zip(bb_params.keys(), p)))
        for p in itertools.product(*bb_params.values())
    ]

    # 3. MACD ì „ëµ íŒŒë¼ë¯¸í„°
    macd_params = {
        'fastperiod': [12, 20],
        'slowperiod': [26, 40],
        'signalperiod': [9, 12]
    }
    macd_grid = [
        (MacdStrategy, dict(zip(macd_params.keys(), p)))
        for p in itertools.product(*macd_params.values())
    ]


    # --- ìƒì„±ëœ ê·¸ë¦¬ë“œë¥¼ í•©ì³ì„œ ë°˜í™˜ ---
    # ì—¬ê¸° ì£¼ì„ì„ í’€ê±°ë‚˜ ì¶”ê°€í•˜ì—¬ ë‹¤ë¥¸ ì „ëµë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
    final_grid = rsi_grid + bb_grid + macd_grid
    # final_grid = macd_grid # MACDë§Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì„ ê²½ìš°
    
    return final_grid


def load_progress():
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except Exception: return {}
    return {}


def save_progress(progress):
    os.makedirs(LOGS_DIR, exist_ok=True)
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def log_realtime(message):
    log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}"
    print(log_message)
    try:
        os.makedirs(LOGS_DIR, exist_ok=True)
        with open(REALTIME_LOG, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    except Exception: pass


def main():
    log_realtime("ğŸš€ ì „ëµ í”Œë«í¼ ì˜µí‹°ë§ˆì´ì € ì‹œì‘")
    
    param_grid = generate_param_grid()
    total_jobs = len(param_grid)
    log_realtime(f"ì´ {total_jobs:,}ê°œì˜ íŒŒë¼ë¯¸í„° ì¡°í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")

    progress = load_progress()
    done_keys = set(progress.get('done_keys', []))

    pending_jobs = []
    for strategy_class, params in param_grid:
        key = f"{strategy_class.__name__}_{'_'.join([f'{k}{v}' for k, v in params.items()])}"
        if key not in done_keys:
            pending_jobs.append((strategy_class, params))

    log_realtime(f"ëŒ€ê¸° ì‘ì—…: {len(pending_jobs):,}ê°œ (ì´ë¯¸ ì™„ë£Œ: {len(done_keys):,}ê°œ)")

    if not pending_jobs:
        log_realtime("âœ… ëª¨ë“  ì‘ì—…ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì›Œì»¤ ìˆ˜ ì¡°ì ˆ
    max_workers = max(1, (multiprocessing.cpu_count() or 2) - 1)
    log_realtime(f"ë³‘ë ¬ ì›Œì»¤ ìˆ˜: {max_workers}ê°œ")

    results = []
    
    with ProcessPoolExecutor(max_workers=max_workers, initializer=init_worker) as executor:
        futures = {executor.submit(run_single_backtest, job): job for job in pending_jobs}
        
        for i, future in enumerate(as_completed(futures), 1):
            try:
                result = future.result()
                results.append(result)
                done_keys.add(result['key'])

                sign = 'ğŸŸ¢' if result['total_return_pct'] > 0 else 'ğŸ”´'
                log_realtime(f"{sign} {i}/{len(pending_jobs)} | {result['key']} => "
                             f"Return={result['total_return_pct']:.2f}%, MDD={result['mdd_pct']:.2f}%")

            except Exception as e:
                log_realtime(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {futures[future]} - {e}")

            if i % 5 == 0 or i == len(pending_jobs):
                progress['done_keys'] = list(done_keys)
                save_progress(progress)
                
                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                if results:
                    pd.DataFrame(results).to_csv(RESULTS_CSV, index=False, encoding='utf-8-sig')

    log_realtime("\nâœ… ìµœì í™” ì™„ë£Œ")
    if results:
        df_results = pd.DataFrame(results)
        df_sorted = df_results.sort_values(by='total_return_pct', ascending=False)
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        df_sorted.to_csv(RESULTS_CSV, index=False, encoding='utf-8-sig')
        log_realtime(f"ğŸ’¾ ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {RESULTS_CSV}")

        log_realtime("\nğŸ† TOP 10 ì „ëµ (ìˆ˜ìµë¥  ê¸°ì¤€):")
        print(df_sorted.head(10).to_string())


if __name__ == '__main__':
    main()
