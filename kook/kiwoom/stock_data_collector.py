import os
import json
from datetime import datetime, timedelta
import requests
import pandas as pd
import time
from io import StringIO
import sys
import os
import platform
import importlib.util

# ìš´ì˜ì²´ì œë³„ telegram ëª¨ë“ˆ ê²½ë¡œ ì„¤ì •
if platform.system() == "Windows":
    telegram_path = "C:/work/GitHub/moapick-web/py/telegram.py"
else:
    telegram_path = "/opt/my/py/telegram.py"  # ì„ì‹œ ê²½ë¡œ

# ì§ì ‘ íŒŒì¼ì—ì„œ ëª¨ë“ˆ ë¡œë“œ (íŒ¨í‚¤ì§€ ì¶©ëŒ ë°©ì§€)
spec = importlib.util.spec_from_file_location("telegram_module", telegram_path)
telegram_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(telegram_module)
send_telegram = telegram_module.send

import platform

# ìš´ì˜ì²´ì œë³„ ë°ì´í„° ì €ì¥ ê²½ë¡œ ì„¤ì •
if platform.system() == "Windows":
    DATA_DIR = "C:/work/GitHub/moapick-web/py/kiwoom/data"
    JSON_PATH = "C:/work/GitHub/moapick-web/py/kiwoom/stock_data_collector.json"
else:
    # Linux ê²½ë¡œëŠ” ë‚˜ì¤‘ì— ì‚¬ìš©ìê°€ ì„¤ì •í•  ì˜ˆì •
    DATA_DIR = "/opt/my/py/kiwoom/data"  # ì„ì‹œ ê²½ë¡œ
    JSON_PATH = "/opt/my/py/kiwoom/stock_data_collector.json"  # ì„ì‹œ ê²½ë¡œ

def send_error_telegram(code, error_type, error_msg, url=None):
    """
    ì˜¤ë¥˜ ë°œìƒ ì‹œ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
    """
    try:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        message = f"ğŸš¨ [ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜]\n\n"
        message += f"ğŸ“… ì‹œê°„: {current_time}\n"
        message += f"ğŸ“Š ì¢…ëª©ì½”ë“œ: {code}\n"
        message += f"âŒ ì˜¤ë¥˜ìœ í˜•: {error_type}\n"
        message += f"ğŸ’¬ ì˜¤ë¥˜ë‚´ìš©: {error_msg}\n"
        
        if url:
            message += f"ğŸ”— URL: {url}\n"
        
        send_telegram(message)
        print(f"[í…”ë ˆê·¸ë¨] ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"[í…”ë ˆê·¸ë¨ ì˜¤ë¥˜] ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ë„¤ì´ë²„ API URL
STOCK_URL = "https://api.stock.naver.com/chart/domestic/item/{code}/day?startDateTime={start}0000&endDateTime={end}0000"
# ì½”ìŠ¤í”¼ ì§€ìˆ˜ API URL ì¶”ê°€
KOSPI_INDEX_URL = "https://api.stock.naver.com/chart/domestic/index/KOSPI/day?startDateTime={start}0000&endDateTime={end}0000"

def get_broker_codes():
    """
    KRXì—ì„œ KOSPI/KOSDAQ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì˜´ (ì½”ë„¥ìŠ¤/ETF ì œì™¸)
    """
    try:
        url = "http://kind.krx.co.kr/corpgeneral/corpList.do"
        kospi_params = {"method": "download", "marketType": "stockMkt"}
        kosdaq_params = {"method": "download", "marketType": "kosdaqMkt"}
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        # KOSPI
        print("[ì •ë³´] KOSPI ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        try:
            resp_kospi = requests.get(url, params=kospi_params, headers=headers, timeout=30)
            print(f"[ì •ë³´] KOSPI ì‘ë‹µ ìƒíƒœ: {resp_kospi.status_code}")
            if resp_kospi.status_code != 200:
                print(f"[ì˜¤ë¥˜] KOSPI API ì˜¤ë¥˜: {resp_kospi.text[:200]}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] KOSPI API ìš”ì²­ ì‹¤íŒ¨: {e}")
            resp_kospi = None
        time.sleep(2)
        
        # KOSDAQ
        print("[ì •ë³´] KOSDAQ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        try:
            resp_kosdaq = requests.get(url, params=kosdaq_params, headers=headers, timeout=30)
            print(f"[ì •ë³´] KOSDAQ ì‘ë‹µ ìƒíƒœ: {resp_kosdaq.status_code}")
            if resp_kosdaq.status_code != 200:
                print(f"[ì˜¤ë¥˜] KOSDAQ API ì˜¤ë¥˜: {resp_kosdaq.text[:200]}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] KOSDAQ API ìš”ì²­ ì‹¤íŒ¨: {e}")
            resp_kosdaq = None
        time.sleep(2)
        
        # DataFrame ë³€í™˜
        print("[ì •ë³´] DataFrame ë³€í™˜ ì¤‘...")
        
        try:
            kospi_df = pd.read_html(StringIO(resp_kospi.text))[0]
            print(f"[ì •ë³´] KOSPI DataFrame í¬ê¸°: {kospi_df.shape}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] KOSPI DataFrame ë³€í™˜ ì‹¤íŒ¨: {e}")
            print(f"[ë””ë²„ê¹…] KOSPI ì‘ë‹µ ë‚´ìš© ì¼ë¶€: {resp_kospi.text[:500]}")
            kospi_df = pd.DataFrame()
        
        try:
            kosdaq_df = pd.read_html(StringIO(resp_kosdaq.text))[0]
            print(f"[ì •ë³´] KOSDAQ DataFrame í¬ê¸°: {kosdaq_df.shape}")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] KOSDAQ DataFrame ë³€í™˜ ì‹¤íŒ¨: {e}")
            print(f"[ë””ë²„ê¹…] KOSDAQ ì‘ë‹µ ë‚´ìš© ì¼ë¶€: {resp_kosdaq.text[:500]}")
            kosdaq_df = pd.DataFrame()
        
        # ë¹ˆ DataFrame ì²´í¬
        if kospi_df.empty:
            print("[ê²½ê³ ] KOSPI ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        else:
            kospi_df['ì¢…ëª©ì½”ë“œ'] = kospi_df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        
        if kosdaq_df.empty:
            print("[ê²½ê³ ] KOSDAQ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        else:
            kosdaq_df['ì¢…ëª©ì½”ë“œ'] = kosdaq_df['ì¢…ëª©ì½”ë“œ'].astype(str).str.zfill(6)
        
        # ì½”ë“œì™€ íšŒì‚¬ëª… ë§¤í•‘ ìƒì„±
        code_name_map = {}
        
        # KOSPI ì¢…ëª©ë“¤
        for _, row in kospi_df.iterrows():
            code = row['ì¢…ëª©ì½”ë“œ']
            name = row['íšŒì‚¬ëª…']
            code_name_map[code] = {'name': name, 'market': 'KOSPI'}
        
        # KOSDAQ ì¢…ëª©ë“¤
        for _, row in kosdaq_df.iterrows():
            code = row['ì¢…ëª©ì½”ë“œ']
            name = row['íšŒì‚¬ëª…']
            code_name_map[code] = {'name': name, 'market': 'KOSDAQ'}
        
        codes = list(code_name_map.keys())
        kospi_count = len([c for c in codes if code_name_map[c]['market'] == 'KOSPI'])
        kosdaq_count = len([c for c in codes if code_name_map[c]['market'] == 'KOSDAQ'])
        print(f"[ì •ë³´] ì¢…ëª© ìˆ˜ì§‘ ì™„ë£Œ: KOSPI {kospi_count}ê°œ, KOSDAQ {kosdaq_count}ê°œ")
        
        return codes, code_name_map
    except Exception as e:
        print(f"[ê²½ê³ ] KRX ì¢…ëª©ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return [], {}

def fetch_stock_data(code, start_date, end_date):
    """
    ë„¤ì´ë²„ APIì—ì„œ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    """
    try:
        url = STOCK_URL.format(code=code, start=start_date, end=end_date)
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers)
        
        if resp.status_code != 200:
            error_msg = f"HTTP {resp.status_code} ì˜¤ë¥˜"
            print(f"[ì˜¤ë¥˜] {code} ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {resp.status_code}")
            print(f"[URL] {url}")
            send_error_telegram(code, "API ìš”ì²­ ì‹¤íŒ¨", error_msg, url)
            print(f"[ì¢…ë£Œ] ì˜¤ë¥˜ë¡œ ì¸í•´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit(1)
            
        data = resp.json()
        if not data:
            print(f"[ê²½ê³ ] {code} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return None
            
        df = pd.DataFrame(data)
        
        # ì»¬ëŸ¼ ì¶”ì¶œ ë° ì´ë¦„ ë³€ê²½
        if 'localDate' in df.columns:
            df = df[['localDate', 'closePrice', 'openPrice', 'highPrice', 'lowPrice', 'accumulatedTradingVolume']]
            df.rename(columns={
                'localDate': 'date',
                'closePrice': 'close',
                'openPrice': 'open',
                'highPrice': 'high',
                'lowPrice': 'low',
                'accumulatedTradingVolume': 'volume'
            }, inplace=True)
            
            # date ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            df['date'] = pd.to_datetime(df['date'])
        else:
            print(f"[ê²½ê³ ] {code} ë°ì´í„° í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„")
            return None
            
        return df
        
    except Exception as e:
        error_msg = str(e)
        print(f"[ì˜¤ë¥˜] {code} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        send_error_telegram(code, "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", error_msg)
        return None

def fetch_kospi_index_data(start_date, end_date):
    """
    ë„¤ì´ë²„ APIì—ì„œ ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    """
    try:
        url = KOSPI_INDEX_URL.format(start=start_date, end=end_date)
        
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers)
        
        if resp.status_code != 200:
            error_msg = f"HTTP {resp.status_code} ì˜¤ë¥˜"
            print(f"[ì˜¤ë¥˜] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {resp.status_code}")
            print(f"[URL] {url}")
            send_error_telegram("KOSPI", "ì§€ìˆ˜ API ìš”ì²­ ì‹¤íŒ¨", error_msg, url)
            return None
            
        data = resp.json()
        if not data:
            print(f"[ê²½ê³ ] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return None
            
        df = pd.DataFrame(data)
        
        # ì»¬ëŸ¼ ì¶”ì¶œ ë° ì´ë¦„ ë³€ê²½
        if 'localDate' in df.columns:
            df = df[['localDate', 'closePrice', 'openPrice', 'highPrice', 'lowPrice']]
            df.rename(columns={
                'localDate': 'date',
                'closePrice': 'close',
                'openPrice': 'open',
                'highPrice': 'high',
                'lowPrice': 'low'
            }, inplace=True)
            
            # volume ì»¬ëŸ¼ ì¶”ê°€ (ì§€ìˆ˜ëŠ” ê±°ë˜ëŸ‰ì´ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •)
            df['volume'] = 0
            
            # date ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            df['date'] = pd.to_datetime(df['date'])
        else:
            print(f"[ê²½ê³ ] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„")
            return None
            
        return df
        
    except Exception as e:
        error_msg = str(e)
        print(f"[ì˜¤ë¥˜] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        send_error_telegram("KOSPI", "ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", error_msg)
        return None

def get_csv_filename(code, market, name):
    """
    CSV íŒŒì¼ëª… ìƒì„± (market_code_name í˜•ì‹)
    """
    safe_name = name.replace('/', '_').replace('\\', '_').replace(':', '_').replace('*', '_').replace('?', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
    return f"{DATA_DIR}/{market}_{code}_{safe_name}.csv"

def get_kospi_index_filename():
    """
    ì½”ìŠ¤í”¼ ì§€ìˆ˜ CSV íŒŒì¼ëª… ìƒì„±
    """
    return f"{DATA_DIR}/INDEX_KOSPI_ì½”ìŠ¤í”¼ì§€ìˆ˜.csv"

def save_stock_data(code, df, code_name_map):
    """
    ì£¼ì‹ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (market_code_name í˜•ì‹)
    """
    try:
        # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # ì¢…ëª© ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        if code in code_name_map:
            market = code_name_map[code]['market']
            name = code_name_map[code]['name']
            filename = get_csv_filename(code, market, name)
        else:
            # ì¢…ëª© ì •ë³´ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í˜•ì‹ ì‚¬ìš©
            filename = f"{DATA_DIR}/UNKNOWN_{code}.csv"
        
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"[ì„±ê³µ] {code} ë°ì´í„° ì €ì¥: {filename}")
        return filename
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {code} ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def save_kospi_index_data(df):
    """
    ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
    """
    try:
        # data í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        os.makedirs(DATA_DIR, exist_ok=True)
        
        filename = get_kospi_index_filename()
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"[ì„±ê³µ] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ì €ì¥: {filename}")
        return filename
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def find_existing_csv_file(code, market, name):
    """
    ê¸°ì¡´ CSV íŒŒì¼ ì°¾ê¸°
    """
    if not os.path.exists(DATA_DIR):
        return None
    
    # ì •í™•í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì°¾ê¸°
    expected_filename = get_csv_filename(code, market, name)
    if os.path.exists(expected_filename):
        return expected_filename
    
    # ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ ì°¾ê¸° (ì½”ë“œë§Œìœ¼ë¡œ)
    for file in os.listdir(DATA_DIR):
        if file.startswith(f"{market}_{code}_") and file.endswith(".csv"):
            return os.path.join(DATA_DIR, file)
    
    return None

def find_existing_kospi_index_file():
    """
    ê¸°ì¡´ ì½”ìŠ¤í”¼ ì§€ìˆ˜ CSV íŒŒì¼ ì°¾ê¸°
    """
    if not os.path.exists(DATA_DIR):
        return None
    
    filename = get_kospi_index_filename()
    if os.path.exists(filename):
        return filename
    
    return None

def load_existing_csv_data(filepath):
    """
    ê¸°ì¡´ CSV íŒŒì¼ ë¡œë“œ
    """
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        # date ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        df['date'] = pd.to_datetime(df['date'])
        return df
    except Exception as e:
        print(f"[ì˜¤ë¥˜] CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def merge_and_save_data(code, existing_df, new_df, market, name):
    """
    ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„°ë¥¼ ë³‘í•©í•˜ì—¬ ì €ì¥
    """
    try:
        # ë‚ ì§œ ì»¬ëŸ¼ íƒ€ì… í†µì¼
        if existing_df is not None and not existing_df.empty:
            existing_df['date'] = pd.to_datetime(existing_df['date'])
        if new_df is not None and not new_df.empty:
            new_df['date'] = pd.to_datetime(new_df['date'])
        
        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['date']).sort_values('date')
        
        # ì €ì¥
        filename = get_csv_filename(code, market, name)
        combined_df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"[ì„±ê³µ] {code} ë°ì´í„° ë³‘í•© ì €ì¥: {filename}")
        return filename
    except Exception as e:
        error_msg = str(e)
        print(f"[ì˜¤ë¥˜] {code} ë°ì´í„° ë³‘í•© ì‹¤íŒ¨: {e}")
        send_error_telegram(code, "ë°ì´í„° ë³‘í•© ì‹¤íŒ¨", error_msg)
        print(f"[ì¢…ë£Œ] ë³‘í•© ì˜¤ë¥˜ë¡œ ì¸í•´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)

def merge_and_save_kospi_index_data(existing_df, new_df):
    """
    ê¸°ì¡´ ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„°ë¥¼ ë³‘í•©í•˜ì—¬ ì €ì¥
    """
    try:
        # ë‚ ì§œ ì»¬ëŸ¼ íƒ€ì… í†µì¼
        if existing_df is not None and not existing_df.empty:
            existing_df['date'] = pd.to_datetime(existing_df['date'])
        if new_df is not None and not new_df.empty:
            new_df['date'] = pd.to_datetime(new_df['date'])
        
        # ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
        combined_df = combined_df.drop_duplicates(subset=['date']).sort_values('date')
        
        # ì €ì¥
        filename = get_kospi_index_filename()
        combined_df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"[ì„±ê³µ] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ë³‘í•© ì €ì¥: {filename}")
        return filename
    except Exception as e:
        error_msg = str(e)
        print(f"[ì˜¤ë¥˜] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ë³‘í•© ì‹¤íŒ¨: {e}")
        send_error_telegram("KOSPI", "ì§€ìˆ˜ ë°ì´í„° ë³‘í•© ì‹¤íŒ¨", error_msg)
        print(f"[ì¢…ë£Œ] ë³‘í•© ì˜¤ë¥˜ë¡œ ì¸í•´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)

def get_date_range_for_collection(code, info):
    """
    ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„ë¥¼ ê²°ì •
    """
    today = datetime.now()
    
    # JSONì—ì„œ start_date ê°€ì ¸ì˜¤ê¸°
    start_date_str = info.get('start_date', '20200101')
    try:
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d').strftime('%Y%m%d')
    except:
        start_date = "20200101"
    
    # ê¸°ì¡´ CSV íŒŒì¼ í™•ì¸
    market = info.get('market', 'UNKNOWN')
    name = info.get('name', 'UNKNOWN')
    existing_file = find_existing_csv_file(code, market, name)
    
    if existing_file:
        # ê¸°ì¡´ íŒŒì¼ì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
        existing_df = load_existing_csv_data(existing_file)
        if existing_df is not None and not existing_df.empty:
            latest_date = existing_df['date'].max()
            # ë‹¤ìŒë‚ ë¶€í„° ì‹œì‘
            next_date = latest_date + timedelta(days=1)
            start_date = next_date.strftime('%Y%m%d')
    
    # ì¢…ë£Œì¼ì€ ì˜¤ëŠ˜
    end_date = today.strftime('%Y%m%d')
    
    return start_date, end_date

def check_and_fill_missing_start_data(code, info):
    """
    ì‹œì‘ ë¶€ë¶„ ëˆ„ë½ ë°ì´í„° í™•ì¸ ë° ì±„ìš°ê¸°
    """
    market = info.get('market', 'UNKNOWN')
    name = info.get('name', 'UNKNOWN')
    start_date_str = info.get('start_date', '20200101')
    
    # ê¸°ì¡´ CSV íŒŒì¼ í™•ì¸
    existing_file = find_existing_csv_file(code, market, name)
    
    if not existing_file:
        print(f"[ì •ë³´] {code}: ê¸°ì¡´ íŒŒì¼ ì—†ìŒ, ì²˜ìŒë¶€í„° ìˆ˜ì§‘ í•„ìš”")
        return False
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    existing_df = load_existing_csv_data(existing_file)
    if existing_df is None or existing_df.empty:
        print(f"[ê²½ê³ ] {code}: ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
        return False
    
    # ì‹œì‘ì¼ í™•ì¸
    try:
        target_start = datetime.strptime(start_date_str, '%Y-%m-%d')
        actual_start = existing_df['date'].min()
        
        if actual_start > target_start:
            print(f"[ë°œê²¬] {code}: ì‹œì‘ ë¶€ë¶„ ëˆ„ë½ ë°ì´í„° ë°œê²¬")
            print(f"  - ëª©í‘œ ì‹œì‘ì¼: {target_start.strftime('%Y-%m-%d')}")
            print(f"  - ì‹¤ì œ ì‹œì‘ì¼: {actual_start.strftime('%Y-%m-%d')}")
            
            # ëˆ„ë½ëœ ê¸°ê°„ ë°ì´í„° ìˆ˜ì§‘
            missing_start_date = target_start.strftime('%Y%m%d')
            missing_end_date = (actual_start - timedelta(days=1)).strftime('%Y%m%d')
            
            print(f"[ìˆ˜ì§‘] {code}: ëˆ„ë½ ê¸°ê°„ {missing_start_date} ~ {missing_end_date}")
            
            missing_df = fetch_stock_data(code, missing_start_date, missing_end_date)
            if missing_df is not None and not missing_df.empty:
                # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
                merged_file = merge_and_save_data(code, missing_df, existing_df, market, name)
                if merged_file:
                    print(f"[ì™„ë£Œ] {code}: ëˆ„ë½ ë°ì´í„° ì±„ìš°ê¸° ì™„ë£Œ")
                    return True
            
            return False
        else:
            print(f"[í™•ì¸] {code}: ì‹œì‘ ë¶€ë¶„ ë°ì´í„° ì™„ë£Œ")
            return True
            
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {code} ì‹œì‘ ë¶€ë¶„ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

# collector.json ë¡œë“œ/ì €ì¥

def load_collector_json():
    if os.path.exists(JSON_PATH):
        with open(JSON_PATH, encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_collector_json(data):
    with open(JSON_PATH, "w", encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ìƒì¥íì§€ ì—¬ë¶€ í™•ì¸ (ë„¤ì´ë²„ API ì‘ë‹µìœ¼ë¡œ íŒë‹¨)
def is_delisted(code):
    """
    ë„¤ì´ë²„ API ì‘ë‹µìœ¼ë¡œ ìƒì¥íì§€ ì—¬ë¶€ í™•ì¸
    """
    try:
        # ìµœê·¼ 30ì¼ ë°ì´í„° ìš”ì²­
        end_date = datetime.now().strftime("%Y%m%d")
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y%m%d")
        
        df = fetch_stock_data(code, start_date, end_date)
        if df is None or df.empty:
            return True
        return False
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {code} ìƒì¥íì§€ í™•ì¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return True

# ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def collect_data_for_code(code, info, code_name_map):
    """
    ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ë° info ìƒíƒœ ê°±ì‹ 
    """
    print(f"[ìˆ˜ì§‘ ì‹œì‘] {code}")
    
    try:
        # ì‹œì‘ ë¶€ë¶„ ëˆ„ë½ ë°ì´í„° í™•ì¸ ë° ì±„ìš°ê¸°
        if not info.get('start_date_complet', False):
            if check_and_fill_missing_start_data(code, info):
                info['start_date_complet'] = True
        
        # ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„ ê²°ì •
        start_date, end_date = get_date_range_for_collection(code, info)
        
        # ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìœ¼ë©´ ì´ë¯¸ ì™„ë£Œëœ ê²ƒ
        if start_date > end_date:
            print(f"[ì™„ë£Œ] {code}: ì´ë¯¸ ìµœì‹  ë°ì´í„° ë³´ìœ ")
            info['updated'] = False
            return
        
        # ë°ì´í„° ìˆ˜ì§‘
        df = fetch_stock_data(code, start_date, end_date)
        
        if df is None or df.empty:
            print(f"[ì‹¤íŒ¨] {code}: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return
        
        # ê¸°ì¡´ íŒŒì¼ê³¼ ë³‘í•© ë˜ëŠ” ìƒˆë¡œ ì €ì¥
        # code_name_mapì˜ ì •ë³´ë¥¼ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ JSON ì •ë³´ ì‚¬ìš©
        if code in code_name_map:
            market = code_name_map[code]['market']
            name = code_name_map[code]['name']
        else:
            market = info.get('market', 'UNKNOWN')
            name = info.get('name', 'UNKNOWN')
        existing_file = find_existing_csv_file(code, market, name)
        
        if existing_file:
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë³‘í•©
            existing_df = load_existing_csv_data(existing_file)
            if existing_df is not None:
                saved_file = merge_and_save_data(code, existing_df, df, market, name)
            else:
                saved_file = save_stock_data(code, df, code_name_map)
        else:
            # ìƒˆë¡œ ì €ì¥
            saved_file = save_stock_data(code, df, code_name_map)
        
        if saved_file:
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            if start_date == "20200101":  # ì²˜ìŒë¶€í„° ìˆ˜ì§‘í•œ ê²½ìš°
                info['start_date_complet'] = True
            
            # ìµœì‹  ë°ì´í„°ê¹Œì§€ ìˆ˜ì§‘í–ˆëŠ”ì§€ í™•ì¸
            if end_date == datetime.now().strftime("%Y%m%d"):
                info['end_date_complet'] = True
                info['process'] = False  # ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ë” ì´ìƒ ì²˜ë¦¬ ë¶ˆí•„ìš”
            else:
                # ì•„ì§ ìµœì‹ ì´ ì•„ë‹ˆë©´ ê³„ì† ì²˜ë¦¬ í•„ìš”
                info['process'] = True
            
            print(f"[ì„±ê³µ] {code}: {start_date} ~ {end_date} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            print(f"[ì‹¤íŒ¨] {code}: ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"[ì˜¤ë¥˜] {code} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

def collect_kospi_index_data():
    """
    ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
    """
    print(f"[ìˆ˜ì§‘ ì‹œì‘] ì½”ìŠ¤í”¼ ì§€ìˆ˜")
    
    try:
        # ê¸°ì¡´ íŒŒì¼ í™•ì¸
        existing_file = find_existing_kospi_index_file()
        
        # ìˆ˜ì§‘í•  ë‚ ì§œ ë²”ìœ„ ê²°ì •
        today = datetime.now()
        start_date = "19830103"  # ì½”ìŠ¤í”¼ ì§€ìˆ˜ ì‹œì‘ì¼ (1983ë…„ 1ì›” 3ì¼)
        end_date = today.strftime('%Y%m%d')
        
        if existing_file:
            # ê¸°ì¡´ íŒŒì¼ì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
            existing_df = load_existing_csv_data(existing_file)
            if existing_df is not None and not existing_df.empty:
                latest_date = existing_df['date'].max()
                # ë‹¤ìŒë‚ ë¶€í„° ì‹œì‘
                next_date = latest_date + timedelta(days=1)
                start_date = next_date.strftime('%Y%m%d')
        
        # ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìœ¼ë©´ ì´ë¯¸ ì™„ë£Œëœ ê²ƒ
        if start_date > end_date:
            print(f"[ì™„ë£Œ] ì½”ìŠ¤í”¼ ì§€ìˆ˜: ì´ë¯¸ ìµœì‹  ë°ì´í„° ë³´ìœ ")
            return
        
        # ë°ì´í„° ìˆ˜ì§‘
        df = fetch_kospi_index_data(start_date, end_date)
        
        if df is None or df.empty:
            print(f"[ì‹¤íŒ¨] ì½”ìŠ¤í”¼ ì§€ìˆ˜: ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return
        
        # ê¸°ì¡´ íŒŒì¼ê³¼ ë³‘í•© ë˜ëŠ” ìƒˆë¡œ ì €ì¥
        if existing_file:
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë³‘í•©
            existing_df = load_existing_csv_data(existing_file)
            if existing_df is not None:
                saved_file = merge_and_save_kospi_index_data(existing_df, df)
            else:
                saved_file = save_kospi_index_data(df)
        else:
            # ìƒˆë¡œ ì €ì¥
            saved_file = save_kospi_index_data(df)
        
        if saved_file:
            print(f"[ì„±ê³µ] ì½”ìŠ¤í”¼ ì§€ìˆ˜: {start_date} ~ {end_date} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            print(f"[ì‹¤íŒ¨] ì½”ìŠ¤í”¼ ì§€ìˆ˜: ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì½”ìŠ¤í”¼ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        send_error_telegram("KOSPI", "ì§€ìˆ˜ ìˆ˜ì§‘ ì˜¤ë¥˜", str(e))

def main():
    # ì½”ìŠ¤í”¼ ì§€ìˆ˜ ìˆ˜ì§‘ ë¨¼ì € ì‹¤í–‰
    print("=" * 50)
    print("[ì½”ìŠ¤í”¼ ì§€ìˆ˜ ìˆ˜ì§‘ ì‹œì‘]")
    collect_kospi_index_data()
    print("=" * 50)
    
    codes, code_name_map = get_broker_codes()
    collector = load_collector_json()

    # ì¦ê¶Œì‚¬ ì½”ë“œì™€ ëŒ€ì¡°í•´ì„œ ì—†ìœ¼ë©´ collectorì— ì¶”ê°€, ìˆìœ¼ë©´ market ì •ë³´ ì—…ë°ì´íŠ¸
    for code in codes:
        if code not in collector:
            # code_name_mapì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            if code in code_name_map:
                market = code_name_map[code]['market']
                name = code_name_map[code]['name']
            else:
                market = "UNKNOWN"
                name = "UNKNOWN"
            
            # í˜¸ìŠ¤íŒ©/ìŠ¤íŒ© ì¢…ëª©ì€ ì²˜ë¦¬ ì œì™¸
            process_status = False if ("í˜¸ìŠ¤íŒ©" in name or "ìŠ¤íŒ©" in name) else True
            
            collector[code] = {
                "market": market,
                "name": name,
                "start_date": "2020-01-01",  # ê¸°ë³¸ê°’
                "start_date_complet": False,
                "end_date_complet": False,
                "process": process_status,  # í˜¸ìŠ¤íŒ© ì¢…ëª©ì€ ì²˜ë¦¬ ì œì™¸
                "delisted": False,
                "last_update": None
            }
        else:
            # ê¸°ì¡´ ì¢…ëª©ì´ ìˆìœ¼ë©´ market ì •ë³´ ì—…ë°ì´íŠ¸ (code_name_mapì— ìˆëŠ” ê²½ìš°)
            if code in code_name_map:
                old_market = collector[code].get('market', 'UNKNOWN')
                new_market = code_name_map[code]['market']
                collector[code]['market'] = new_market
                collector[code]['name'] = code_name_map[code]['name']
                
                # ETFë¡œ ë³€ê²½ëœ ê²½ìš° ê°•ì œë¡œ ë‹¤ì‹œ ìˆ˜ì§‘
                # if old_market != 'ETF' and new_market == 'ETF': # ETF ê´€ë ¨ ë¡œì§ ì œê±°
                #     print(f"[ì—…ë°ì´íŠ¸] {code}: ETFë¡œ ë³€ê²½ë¨ - ê°•ì œ ì¬ìˆ˜ì§‘ ì„¤ì •")
                #     collector[code]['process'] = True
                #     collector[code]['start_date_complet'] = False
                #     collector[code]['end_date_complet'] = False
                # else:
                print(f"[ì—…ë°ì´íŠ¸] {code}: market ì •ë³´ ì—…ë°ì´íŠ¸ - {new_market}")

    # (collectorì—ë§Œ ìˆê³  ì‹¤ì œ ì½”ë“œë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ì¢…ëª©ì€ ì‚­ì œí•˜ì§€ ì•ŠìŒ)

    for code, info in collector.items():
        # ìŠ¤íŒ© ì¢…ëª© ì œì™¸
        name = info.get('name', '')
        if 'í˜¸ìŠ¤íŒ©' in name or 'ìŠ¤íŒ©' in name:
            print(f"{code}: ìŠ¤íŒ© ì¢…ëª© ì œì™¸ ({name})")
            continue
        
        # ETF ì¢…ëª©ì€ ê°•ì œë¡œ ì²˜ë¦¬ (market ì •ë³´ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´)
        # if info.get('market') == 'ETF': # ETF ê´€ë ¨ ë¡œì§ ì œê±°
        #     print(f"{code}: ETF ì¢…ëª© ê°•ì œ ì²˜ë¦¬ ({name})")
        #     info['process'] = True  # ê°•ì œë¡œ ì²˜ë¦¬ í•„ìš”ë¡œ ì„¤ì •
        #     info['start_date_complet'] = False  # ì‹œì‘ ë¶€ë¶„ ë‹¤ì‹œ ìˆ˜ì§‘
        #     info['end_date_complet'] = False  # ë ë¶€ë¶„ ë‹¤ì‹œ ìˆ˜ì§‘
        
        # ì²˜ë¦¬í•  í•„ìš”ê°€ ì—†ëŠ” ì¢…ëª©ì€ ê±´ë„ˆë›°ê¸° (processê°€ falseì´ê±°ë‚˜ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš°)
        if not info.get("process", False) or (info.get("start_date_complet", False) and info.get("end_date_complet", False)):
            print(f"{code}: ì²˜ë¦¬ ë¶ˆí•„ìš” (process: {info.get('process', False)}, ì™„ë£Œ: {info.get('start_date_complet', False)}/{info.get('end_date_complet', False)})")
            continue
        # ì‹œì‘ë¶€ë¶„ ì´ë¯¸ ì™„ë£Œë©´ íŒ¨ìŠ¤
        if info.get("start_date_complet", False):
            print(f"{code}: ì‹œì‘ë¶€ë¶„ ì´ë¯¸ ì™„ë£Œ (start_date_complet)")
            continue
        # ìƒì¥íì§€ë©´ end_date_complet ì²˜ë¦¬
        if not info.get("end_date_complet", False) and is_delisted(code):
            info["end_date_complet"] = True
            info["delisted"] = True
            print(f"{code}: ìƒì¥íì§€ë¡œ end_date_complet ì²˜ë¦¬")
            continue
        # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
        collect_data_for_code(code, info, code_name_map)
        # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ê¸°ë¡
        info["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ê° ì¢…ëª© ì²˜ë¦¬ í›„ JSON ì €ì¥ (ì§„í–‰ ìƒí™© ë³´ì¡´)
        save_collector_json(collector)
        
        # API í˜¸ì¶œ ì œí•œì„ ìœ„í•œ ëŒ€ê¸°
        time.sleep(0.5)

if __name__ == "__main__":
    main() 