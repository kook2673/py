# -*- coding: utf-8 -*-
"""
ì „ëµ í”Œë«í¼ìš© íŒŒë¼ë¯¸í„° ìµœì í™”(Optimizer) ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” 'strategy_platform.py'ì— ì •ì˜ëœ ë‹¤ì–‘í•œ ì „ëµë“¤ì„ ëŒ€ìƒìœ¼ë¡œ
ì§€ì •ëœ íŒŒë¼ë¯¸í„° ë²”ìœ„ì— ëŒ€í•œ ê·¸ë¦¬ë“œ íƒìƒ‰(Grid Search)ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë©€í‹°í”„ë¡œì„¸ì‹±(ë³‘ë ¬ ì²˜ë¦¬)ì„ í™œìš©í•˜ì—¬ ìµœì í™” ì†ë„ í–¥ìƒ.
- í…ŒìŠ¤íŠ¸í•  ì „ëµ(ì˜ˆ: RSI, ë³¼ë¦°ì € ë°´ë“œ)ì„ ì‰½ê²Œ ì„ íƒí•˜ê³  í•´ë‹¹ ì „ëµì˜ íŒŒë¼ë¯¸í„° ë²”ìœ„ë¥¼ ì§€ì •.
- ì§„í–‰ ìƒí™©ì„ JSON íŒŒì¼ì— ì €ì¥í•˜ì—¬, ìŠ¤í¬ë¦½íŠ¸ê°€ ì¤‘ë‹¨ë˜ë”ë¼ë„ ì´ì–´ì„œ ì‘ì—… ê°€ëŠ¥.
- ìµœì¢… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ Excel ë“±ì—ì„œ ì‰½ê²Œ ë¶„ì„.
"""

import os
import io
import sys

# Windows ì½˜ì†”ì—ì„œ UTF-8 ì¶œë ¥ì´ ê¹¨ì§€ëŠ” ë¬¸ì œ í•´ê²°
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import json
import glob
import itertools
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing
import copy # Added for deepcopy
import numpy as np # Added for np.where
import pprint # Added for pprint

import pandas as pd

from matplotlib.ticker import FuncFormatter
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from tqdm import tqdm # Added for progress bar

import logging
import logging.handlers

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

# ìƒˆë¡œ ë§Œë“  ë°±í…ŒìŠ¤íŒ… í”Œë«í¼ì—ì„œ í•„ìš” í•¨ìˆ˜/í´ë˜ìŠ¤ ì„í¬íŠ¸
from strategy_platform_kr import (
    MovingAverageMomentumStrategy, 
    KospidaqHybridStrategy, 
    SafeAssetRebalancingStrategy, 
    KospiDipBuyingStrategy,
    TurtleStrategy, # í„°í‹€ ì „ëµ ì¶”ê°€
    run_multi_strategy_backtest
)

# ë¡œê¹… ì„¤ì •
log_dir = os.path.join(os.path.dirname(__file__), 'logs')
os.makedirs(log_dir, exist_ok=True)
log_file_path = os.path.join(log_dir, 'walk_forward_optimizer.log')

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.FileHandler(log_file_path, mode='w', encoding='utf-8'), # ë§¤ ì‹¤í–‰ ì‹œ ë¡œê·¸íŒŒì¼ ìƒˆë¡œ ì‘ì„±
        logging.StreamHandler()
    ]
)

# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ---
def setup_korean_font():
    """í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•˜ê³  í°íŠ¸ ì†ì„±ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        # Windows
        font_path = fm.findfont(fm.FontProperties(family='Malgun Gothic'))
        plt.rcParams['font.family'] = 'Malgun Gothic'
    except:
        # Other OS (e.g., Mac)
        try:
            plt.rcParams['font.family'] = 'AppleGothic'
        except:
            # Font not found, matplotlib will use its default
            logging.warning("ê²½ê³ : 'ë§‘ì€ ê³ ë”•' ë˜ëŠ” 'AppleGothic' í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ë˜í”„ì˜ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            pass

# --- ì„¤ì • ë³€ìˆ˜ ---
# ë¡œê·¸ ë° ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
script_dir = os.path.dirname(os.path.abspath(__file__))
LOGS_DIR = os.path.join(script_dir, 'logs')
PROGRESS_FILE = os.path.join(LOGS_DIR, 'Opt_Platform_Progress.json')
RESULTS_CSV = os.path.join(LOGS_DIR, 'Opt_Platform_Results.csv')
REALTIME_LOG = os.path.join(LOGS_DIR, 'Opt_Platform_Realtime.log')

# ë°ì´í„° ê²½ë¡œ (ìˆ˜ì •ë¨)
# ê²½ë¡œ ìˆ˜ì •: binance_test2 í´ë” ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ í´ë”ì˜ binance_test í´ë”ë¥¼ ë°”ë¼ë³´ë„ë¡ ë³€ê²½
DATA_DIR = os.path.abspath(os.path.join(script_dir, '..', 'binance_test', 'data', 'BTC_USDT', '1m'))

# ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ê³µìœ  ë°ì´í„° (ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ë¡œë“œí•˜ê¸° ìœ„í•¨)
_SHARED_DF = None

# =============================================================================
# WFO ì‹¤í–‰ì„ ìœ„í•œ ì „ëµ ë° íŒŒë¼ë¯¸í„° ì„¤ì •
# =============================================================================
STRATEGY_CONFIGS = {
    # 'MA_Momentum': {
    #     'class': MovingAverageMomentumStrategy,
    #     'universe': [], # load_universe_dataì—ì„œ ë™ì ìœ¼ë¡œ ì±„ì›Œì§
    #     'capital_allocation': 0.20,
    #     'params': {
    #         'max_buy_stocks': 30,
    #         'stock_specific_params': {} # load_universe_dataì—ì„œ ë™ì ìœ¼ë¡œ ì±„ì›Œì§
    #     }
    # },
    'Turtle': {
        'class': TurtleStrategy,
        'universe': [], # load_universe_dataì—ì„œ ë™ì ìœ¼ë¡œ ì±„ì›Œì§
        'capital_allocation': 1.0, # í„°í‹€ ì „ëµì— 100% ì§‘ì¤‘
        'params': {
            # ê¸°ë³¸ê°’ - WFOë¥¼ í†µí•´ ìµœì í™”ë  ê°’ë“¤
            'entry_period': 20, 
            'exit_period': 10,
            'atr_period': 20,
            # ê°œì„  ì‚¬í•­ì— ëŒ€í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
            'risk_per_trade': 0.01, # 1íšŒ ê±°ë˜ ì‹œ í¬íŠ¸í´ë¦¬ì˜¤ì˜ 1% ë¦¬ìŠ¤í¬
            'max_positions': 10,    # ìµœëŒ€ ë™ì‹œ ë³´ìœ  ì¢…ëª© ìˆ˜
            'stop_loss_atr_multiplier': 2.0 # 2-ATR ì†ì ˆ
        }
    },
    # 'Kospidaq_Hybrid': {
    #     'class': KospidaqHybridStrategy,
    #     'universe': ['122630', '252670', '233740', '251340'], # KODEX ë ˆë²„ë¦¬ì§€, ì¸ë²„ìŠ¤2X, KOSDAQ150ë ˆë²„ë¦¬ì§€, ì¸ë²„ìŠ¤2X
    #     'capital_allocation': 0.20,
    #     'params': { # ì´ ê°’ë“¤ì€ WFOë¥¼ í†µí•´ out-of-sampleë§ˆë‹¤ ì—…ë°ì´íŠ¸ë¨
    #         '122630': {'small_ma': 5, 'big_ma': 20},
    #         '252670': {'small_ma': 5, 'big_ma': 20},
    #         '233740': {'small_ma': 5, 'big_ma': 20},
    #         '251340': {'small_ma': 5, 'big_ma': 20},
    #     }
    # },
    # 'Safe_Asset': {
    #     'class': SafeAssetRebalancingStrategy,
    #     'universe': ['132030', '148020', '130680', '114260', '138220'], # KOSEF êµ­ê³ ì±„10ë…„, ë‹¨ê¸°í†µì•ˆì±„, êµ­ê³ ì±„3ë…„, G-FOCUS, KODEX ë¯¸êµ­ì±„10ë…„ì„ ë¬¼
    #     'capital_allocation': 0.20,
    #     'params': {} # SafeAssetRebalancingStrategyëŠ” ìì²´ ë¡œì§ ì‚¬ìš©
    # },
    # 'Dip_Buying': {
    #     'class': KospiDipBuyingStrategy,
    #     'universe': ['KOSPI', '122630'], # KOSPI ì§€ìˆ˜ì™€ KODEX ë ˆë²„ë¦¬ì§€ ETF
    #     'capital_allocation': 0.20,
    #     'params': {}
    # }
}


def init_worker():
    """ì›Œì»¤ ì´ˆê¸°í™”: ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— í•œ ë²ˆë§Œ ë¡œë“œ"""
    global _SHARED_DF
    try:
        logging.info("ğŸ“¥ ì›Œì»¤ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # 2025ë…„ 1ì›” ~ 2ì›” ë°ì´í„° ì‚¬ìš© (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ê°„ ë‹¨ì¶•)
        all_files = []
        for month in range(1, 3):
            month_pattern = f'2025-{month:02d}.csv'
            files = glob.glob(os.path.join(DATA_DIR, month_pattern))
            all_files.extend(files)
        
        if not all_files:
            raise RuntimeError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}")
        
        dfs = [pd.read_csv(f, index_col='timestamp', parse_dates=True) for f in sorted(all_files)]
        _SHARED_DF = pd.concat(dfs).sort_index().drop_duplicates()
        logging.info(f"ğŸ‰ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(_SHARED_DF):,}ê°œ ë°ì´í„°")
        
    except Exception as e:
        _SHARED_DF = None
        raise RuntimeError(f'ì›Œì»¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}')


def run_single_backtest(params_tuple):
    """ì›Œì»¤ì—ì„œ ì‹¤í–‰ë  ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    strategy_class, strategy_params = params_tuple
    
    if _SHARED_DF is None:
        raise RuntimeError('ê³µìœ  ë°ì´í„°í”„ë ˆì„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

    # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = run_backtest(
        df_original=_SHARED_DF,
        strategy_class=strategy_class,
        strategy_params=strategy_params,
        trade_type='long_and_short', # ëª¨ë“  ìµœì í™”ëŠ” ë¡±/ìˆ ì–‘ë°©í–¥ìœ¼ë¡œ ì§„í–‰
        initial_capital=10000,
        fee=0.001,
        leverage=10
    )
    
    # ê²°ê³¼ ìš”ì•½
    # íŒŒë¼ë¯¸í„°ë¥¼ ë¬¸ìì—´ í‚¤ë¡œ ë³€í™˜ (JSON í˜¸í™˜)
    param_key = f"{strategy_class.__name__}_{'_'.join([f'{k}{v}' for k, v in strategy_params.items()])}"
    
    out = {
        'key': param_key,
        'strategy': result['strategy'],
        'total_return_pct': result['total_return_pct'],
        'mdd_pct': result['mdd_pct'],
        'num_trades': result['num_trades'],
        'win_rate_pct': result['win_rate_pct'],
    }
    # íŒŒë¼ë¯¸í„°ë“¤ì„ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€
    out.update(strategy_params)
    return out


def generate_param_grid():
    """WFOì˜ ê° í›ˆë ¨ ê¸°ê°„(in-sample)ë§ˆë‹¤ í…ŒìŠ¤íŠ¸í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # MA_Momentum ì „ëµì— ëŒ€í•œ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
    params = {
        'small_ma': [5, 10, 20],
        'big_ma': [60, 120, 200],
        'max_buy_stocks': [10, 20, 30],
        'momentum_threshold': [0.4, 0.6] 
    }
    
    # small_ma < big_ma ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¡°í•©ë§Œ ìƒì„±
    grid = []
    for p in itertools.product(*params.values()):
        param_dict = dict(zip(params.keys(), p))
        if param_dict['small_ma'] < param_dict['big_ma']:
            grid.append(param_dict)
            
    return grid


def generate_param_grid_for_turtle():
    """TurtleStrategyë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    param_grid = []
    entry_periods = [20, 55]
    exit_periods = [10, 20]
    atr_periods = [20] # ATR ê¸°ê°„ì€ ìš°ì„  20ìœ¼ë¡œ ê³ ì •
    
    for entry in entry_periods:
        for exit_p in exit_periods:
            if exit_p < entry: # ì¢…ë£Œ ê¸°ê°„ì€ ì§„ì… ê¸°ê°„ë³´ë‹¤ ì§§ì•„ì•¼ í•¨
                for atr in atr_periods:
                    param_grid.append({
                        'entry_period': entry,
                        'exit_period': exit_p,
                        'atr_period': atr
                    })
    return param_grid

def optimize_turtle_strategy(train_data, turtle_base_config):
    """TurtleStrategyì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    logging.info("[In-Sample] Turtle ì „ëµ ìµœì í™” ì‹œì‘...")
    param_grid_turtle = generate_param_grid_for_turtle()
    best_in_sample_perf_turtle = -float('inf')
    best_params_turtle = None
    
    # ë‹¨ì¼ ì „ëµ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì • í…œí”Œë¦¿ ìƒì„±
    single_strategy_config = {'Turtle': copy.deepcopy(turtle_base_config)}
    single_strategy_config['Turtle']['capital_allocation'] = 1.0

    for params in param_grid_turtle:
        single_strategy_config['Turtle']['params'] = params
        
        equity_df, _ = run_multi_strategy_backtest(
            universe_dfs=train_data,
            strategy_configs=single_strategy_config,
            initial_capital=100_000_000
        )

        if not equity_df.empty:
            total_return = (equity_df['total_equity'].iloc[-1] / equity_df['total_equity'].iloc[0] - 1) * 100
            if total_return > best_in_sample_perf_turtle:
                best_in_sample_perf_turtle = total_return
                best_params_turtle = params

    logging.info(f"[In-Sample] Turtle ì „ëµ ìµœì  íŒŒë¼ë¯¸í„°: {best_params_turtle} (ìˆ˜ìµë¥ : {best_in_sample_perf_turtle:.2f}%)")
    return best_params_turtle

def find_optimal_ma_for_ticker(df: pd.DataFrame, short_range: list, long_range: list) -> dict:
    """íŠ¹ì • ì¢…ëª©(df)ì— ëŒ€í•´ ìµœì ì˜ MA ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤."""
    best_perf = -float('inf')
    best_params = {'small_ma': short_range[0], 'big_ma': long_range[0]}

    # ëª¨ë“  MA ì¡°í•©ì— ëŒ€í•œ ë°±í…ŒìŠ¤íŠ¸
    for s_ma in short_range:
        for l_ma in long_range:
            if s_ma >= l_ma:
                continue

            # MA ê³„ì‚°
            df['ma_short'] = df['close'].rolling(window=s_ma).mean()
            df['ma_long'] = df['close'].rolling(window=l_ma).mean()
            
            # ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŠ¸ ë¡œì§
            df['position'] = np.where(df['ma_short'] > df['ma_long'], 1, 0)
            df['returns'] = df['close'].pct_change()
            df['strategy_returns'] = df['position'].shift(1) * df['returns']
            
            # ìµœì¢… ìˆ˜ìµë¥ 
            cumulative_return = (1 + df['strategy_returns']).cumprod().iloc[-1]
            
            if cumulative_return > best_perf:
                best_perf = cumulative_return
                best_params = {'small_ma': s_ma, 'big_ma': l_ma}
    
    return best_params

def find_optimal_params_for_kospidaq(train_universe: dict) -> dict:
    """Kospidaq_Hybrid ì „ëµì˜ ê° ETFì— ëŒ€í•œ ìµœì  MA ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤."""
    
    tickers = ["122630", "252670", "233740", "251340"]
    short_ma_range = [3, 5, 10, 20]
    long_ma_range = [60, 120]
    
    optimal_params = {}

    for ticker in tickers:
        if ticker in train_universe and not train_universe[ticker].empty:
            df = train_universe[ticker]
            best_ma_pair = find_optimal_ma_for_ticker(df.copy(), short_ma_range, long_ma_range)
            optimal_params[ticker] = best_ma_pair
            
    return optimal_params


def load_progress():
    if os.path.exists(PROGRESS_FILE):
        try:
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except Exception: return {}
    return {}


def save_progress(progress):
    os.makedirs(LOGS_DIR, exist_ok=True)
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def log_realtime(message):
    log_message = f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {message}"
    print(log_message)
    try:
        os.makedirs(LOGS_DIR, exist_ok=True)
        with open(REALTIME_LOG, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    except Exception: pass


def plot_wfo_results(results_data, title='Walk-Forward Optimization Results'):
    """WFO ë° ë©€í‹°-ì „ëµ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”"""
    
    setup_korean_font()
    plt.rcParams['axes.unicode_minus'] = False

    plt.figure(figsize=(15, 8))

    for name, curve in results_data.items():
        if curve.empty:
            continue
        
        equity_curve = curve.iloc[:, 0] if isinstance(curve, pd.DataFrame) else curve
        
        if equity_curve.empty or equity_curve.iloc[0] == 0:
            ret, mdd = 0.0, 0.0
        else:
            ret = (equity_curve.iloc[-1] / equity_curve.iloc[0] - 1) * 100
            rolling_max = equity_curve.cummax()
            drawdown = equity_curve / rolling_max - 1
            mdd = drawdown.min() * 100

        label = f"{name} (Return: {ret:.2f}%, MDD: {mdd:.2f}%)"
        linewidth = 2.5 if name == 'Total Portfolio' else 1.5
        linestyle = '-' if name == 'Total Portfolio' else '--'
        
        plt.plot(equity_curve.index, equity_curve, label=label, linewidth=linewidth, linestyle=linestyle)

    plt.title(title, fontsize=16)
    plt.xlabel('Date', fontsize=12)
    plt.ylabel('Equity', fontsize=12)
    plt.grid(True, which='both', linestyle='--', linewidth=0.5)
    plt.legend()
    plt.yscale('log')
    
    formatter = FuncFormatter(lambda y, _: f'{int(y):,}')
    plt.gca().yaxis.set_major_formatter(formatter)
    
    plt.tight_layout()
    
    img_path = os.path.join(LOGS_DIR, 'WFO_Multi_Strategy_Results_KR.png')
    plt.savefig(img_path)
    logging.info(f"ğŸ“Š ê²°ê³¼ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {img_path}")


def load_universe_data(data_dir, limit=None):
    """ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ í•„ìš”í•œ ëª¨ë“  ì¢…ëª© ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ìœ ë‹ˆë²„ìŠ¤ ë§¤í•‘"""
    universe_dfs = {}
    
    # ì½”ìŠ¤ë‹¥/ì½”ìŠ¤í”¼ 100 ì¢…ëª© ë¡œë“œ
    kospi100_files = glob.glob(os.path.join(data_dir, "kospi100", "*.csv"))
    kosdaq100_files = glob.glob(os.path.join(data_dir, "kosdaq100", "*.csv"))
    
    if not kospi100_files and not kosdaq100_files:
        logging.warning(f"âŒ ì½”ìŠ¤ë‹¥/ì½”ìŠ¤í”¼ 100 ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.join(data_dir, 'kospi100')}")

    for f in kospi100_files:
        ticker = os.path.basename(f).split('_')[0]
        df = pd.read_csv(f, index_col='date', parse_dates=True)
        df.columns = [col.lower() for col in df.columns]
        universe_dfs[ticker] = df

    for f in kosdaq100_files:
        ticker = os.path.basename(f).split('_')[0]
        df = pd.read_csv(f, index_col='date', parse_dates=True)
        df.columns = [col.lower() for col in df.columns]
        universe_dfs[ticker] = df

    # ì¶”ê°€ë¡œ í•„ìš”í•œ ETF ë° ì§€ìˆ˜ ë°ì´í„° ë¡œë“œ
    other_assets = ["122630", "252670", "233740", "251340", "132030", "114800", "130680", "KOSPI", "139260", "148070", "305080"]
    for asset in other_assets:
        search_pattern = os.path.join(data_dir, "etf_index", f"{asset}_*.csv")
        found_files = glob.glob(search_pattern)
        
        if found_files:
            file_path = found_files[0]
            ticker = os.path.basename(file_path).split('_')[0]
            df = pd.read_csv(file_path, index_col='date', parse_dates=True)
            df.columns = [col.lower() for col in df.columns]
            universe_dfs[ticker] = df
        else:
            logging.warning(f"âŒ {asset} ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: íŒ¨í„´({search_pattern})")

    # ë™ì ìœ¼ë¡œ ìœ ë‹ˆë²„ìŠ¤ í• ë‹¹
    ma_momentum_universe = [os.path.basename(f).split('_')[0] for f in kospi100_files + kosdaq100_files]
    
    # stock_list.jsonì—ì„œ ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ
    stock_list_path = os.path.join(script_dir, '..', 'kis', 'stock_list.json')
    stock_specific_params = {}
    try:
        with open(stock_list_path, 'r', encoding='utf-8') as f:
            stock_data = json.load(f)
            # JSON íŒŒì¼ ìµœìƒìœ„ì˜ 'stocks' í‚¤ì— ì ‘ê·¼
            stock_details_dict = stock_data.get('stocks', {})
            # .items()ë¡œ ì¢…ëª©ì½”ë“œì™€ ìƒì„¸ì •ë³´ë¥¼ ìˆœíšŒ
            for ticker, details in stock_details_dict.items():
                # 'small_ma', 'big_ma' í‚¤ë¥¼ ì§ì ‘ ì‚¬ìš©
                ma_short = details.get('small_ma')
                ma_long = details.get('big_ma')
                if ticker and ma_short and ma_long:
                    stock_specific_params[ticker] = {'small_ma': ma_short, 'big_ma': ma_long}
    except FileNotFoundError:
        logging.warning(f"âŒ stock_list.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {stock_list_path}")
    except json.JSONDecodeError:
        logging.warning(f"âŒ stock_list.json íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {stock_list_path}")

    return universe_dfs, ma_momentum_universe, stock_specific_params


def main():
    logging.info("ğŸš€ í•œêµ­ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ WFO ì‹œì‘")
    os.makedirs(LOGS_DIR, exist_ok=True)
    
    # ì „ì²´ ê¸°ê°„ ì„¤ì • (ì›ë˜ëŒ€ë¡œ ë³µì›)
    total_start_date = '2018-01-01'
    total_end_date = datetime.now().strftime('%Y-%m-%d')

    # ë‚ ì§œë¥¼ Timestamp ê°ì²´ë¡œ ë³€í™˜
    total_start_date = pd.to_datetime(total_start_date)
    total_end_date = pd.to_datetime(total_end_date)
    
    # WFO íŒŒë¼ë¯¸í„° (ì›ë˜ëŒ€ë¡œ ë³µì›)
    in_sample_years = 2
    out_of_sample_months = 3
    step_months = 3

    # ì „ì²´ ê¸°ê°„ ë°ì´í„° ë¡œë“œ
    all_stock_data, ma_momentum_universe, stock_specific_params = load_universe_data(os.path.join(script_dir, 'data'))
    
    # 5ê°œ ì „ëµì— ëŒ€í•œ ì„¤ì • (MA_Momentum ì¶”ê°€, ìê¸ˆ 20%ì”© ë¶„ë°°)
    STRATEGY_CONFIGS = {
        # 'MA_Momentum': {
        #     'class': MovingAverageMomentumStrategy,
        #     'universe': ma_momentum_universe,
        #     'params': {
        #         'max_buy_stocks': 30,
        #         'stock_specific_params': stock_specific_params
        #     },
        #     'capital_allocation': 0.20
        # },
        'Turtle': {
            'class': TurtleStrategy,
            'universe': ma_momentum_universe,
            'params': {},
            'capital_allocation': 0.20
        },
        # 'Kospidaq_Hybrid': {
        #     'class': KospidaqHybridStrategy,
        #     'universe': ['122630', '252670', '233740', '251340'],
        #     'params': {},
        #     'capital_allocation': 0.20
        # },
        # 'Safe_Asset': {
        #     'class': SafeAssetRebalancingStrategy,
        #     'universe': ['139260', '148070', '305080', '132030'],
        #     'params': {},
        #     'capital_allocation': 0.20
        # },
        # 'Dip_Buying': {
        #     'class': KospiDipBuyingStrategy,
        #     'universe': ['122630', 'KOSPI'],
        #     'params': {},
        #     'capital_allocation': 0.20
        # }
    }

    # WFO ë£¨í”„
    current_date = total_start_date
    all_oos_equity_curves = []
    all_oos_strategy_curves = {}
    
    # ì²« OOS ê¸°ê°„ì˜ ì´ˆê¸° ìë³¸ì€ ì„¤ì •ëœ initial_capitalë¡œ ì‹œì‘í•©ë‹ˆë‹¤.
    last_equity = 100_000_000 # ì´ˆê¸° ìë³¸ ì„¤ì •
    
    # ê° ì „ëµì˜ ì´ˆê¸° ìë³¸ì„ í• ë‹¹ ë¹„ìœ¨ì— ë”°ë¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    total_allocation = sum(config['capital_allocation'] for config in STRATEGY_CONFIGS.values() if config['capital_allocation'] > 0)
    last_strategy_equity = {
        name: last_equity * (config['capital_allocation'] / total_allocation)
        for name, config in STRATEGY_CONFIGS.items() if config['capital_allocation'] > 0
    }

    while current_date + pd.DateOffset(years=in_sample_years) + pd.DateOffset(months=out_of_sample_months) <= total_end_date:

        train_start_date = current_date
        train_end_date = train_start_date + pd.DateOffset(years=in_sample_years)
        oos_start_date = train_end_date
        oos_end_date = oos_start_date + pd.DateOffset(months=out_of_sample_months)

        if oos_end_date > total_end_date:
            oos_end_date = total_end_date

        logging.info("-" * 80)
        logging.info(f" WFO ?ÑŠì” ?? {train_start_date.date()} ~ {oos_end_date.date()} ".center(80, "#"))
        logging.info(f" In-Sample: {train_start_date.date()} ~ {train_end_date.date()} | Out-of-Sample: {oos_start_date.date()} ~ {oos_end_date.date()} ".center(80, " "))
        logging.info("-" * 80)

        train_data = {ticker: data.loc[train_start_date:train_end_date] for ticker, data in all_stock_data.items()}

        best_params_turtle = optimize_turtle_strategy(train_data, STRATEGY_CONFIGS['Turtle'])
        # optimal_params_kospidaq = find_optimal_params_for_kospidaq(train_data) # é®ê¾ªì†¢?ê¹Šì†•???ê¾¨ì™‚

        oos_config = copy.deepcopy(STRATEGY_CONFIGS)
        if best_params_turtle:
            oos_config['Turtle']['params'] = best_params_turtle
        # oos_config['Kospidaq_Hybrid']['params'] = optimal_params_kospidaq # é®ê¾ªì†¢?ê¹Šì†•???ê¾¨ì™‚

        logging.info("-" * 80)
        logging.info(f" OOS è«›ê¹Šë€’?ã…½ë“ƒ: {oos_start_date.date()} ~ {oos_end_date.date()} ".center(80, "="))

        oos_data = {ticker: data.loc[oos_start_date:oos_end_date] for ticker, data in all_stock_data.items()}

        # --------------------------------------------------------------------------------
        # 3. Out-of-Sample(OOS) ê¸°ê°„ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        # --------------------------------------------------------------------------------
        logging.info(f"\n{'='*21} OOS ë°±í…ŒìŠ¤íŠ¸: {oos_start_date.date()} ~ {oos_end_date.date()} {'='*22}")
        
        oos_equity_df, oos_strategy_equity_curves = run_multi_strategy_backtest(
            universe_dfs=oos_data,
            strategy_configs=oos_config,
            initial_capital=last_equity, # ì´ì „ ê¸°ê°„ì˜ ìµœì¢… ìì‚°ì„ ì´ˆê¸° ìë³¸ìœ¼ë¡œ ì‚¬ìš©
            strategy_initial_capitals=last_strategy_equity # ì´ì „ ê¸°ê°„ì˜ ì „ëµë³„ ìµœì¢… ìì‚°ì„ ì´ˆê¸° ìë³¸ìœ¼ë¡œ ì‚¬ìš©
        )

        if not oos_equity_df.empty:
            # ì „ì²´ ìì‚° ê³¡ì„  ë¦¬ìŠ¤íŠ¸ì— ì´ë²ˆ OOS ê¸°ê°„ì˜ ê²°ê³¼ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
            # ì²«ë²ˆì§¸ oos_equity_dfëŠ” ì´ˆê¸°ìë³¸ í–‰ì„ í¬í•¨í•˜ê³ , ê·¸ ì´í›„ë¶€í„°ëŠ” ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ ì²« í–‰ì„ ì œì™¸í•©ë‹ˆë‹¤.
            if not all_oos_equity_curves:
                all_oos_equity_curves.append(oos_equity_df)
            else:
                all_oos_equity_curves.append(oos_equity_df.iloc[1:])
            
            # ë‹¤ìŒ ë£¨í”„ë¥¼ ìœ„í•´ ìµœì¢… ìì‚°ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            last_equity = oos_equity_df['total_equity'].iloc[-1]

            # ì „ëµë³„ ìì‚° ê³¡ì„ ë„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            for name, curve in oos_strategy_equity_curves.items():
                if name not in all_oos_strategy_curves:
                    all_oos_strategy_curves[name] = []
                
                if not all_oos_strategy_curves[name]:
                     all_oos_strategy_curves[name].append(curve)
                else:
                    all_oos_strategy_curves[name].append(curve.iloc[1:])
                
                # ë‹¤ìŒ ë£¨í”„ë¥¼ ìœ„í•´ ì „ëµë³„ ìµœì¢… ìì‚°ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                if not curve.empty:
                    last_strategy_equity[name] = curve.iloc[-1]

        current_date += pd.DateOffset(months=step_months)

    if not all_oos_equity_curves:
        logging.warning("WFOë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„° ê¸°ê°„ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê° OOS ê¸°ê°„ì˜ ìì‚° ê³¡ì„ ì„ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    compounded_equity = pd.concat(all_oos_equity_curves)

    # ê°œë³„ ì „ëµ ìì‚° ê³¡ì„ ë„ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
    final_strategy_results = {}
    for name, curves in all_oos_strategy_curves.items():
        if curves:
            final_strategy_results[name] = pd.concat(curves)

    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ---
    logging.info("\n" + "="*50)
    logging.info("âœ… ìµœì¢… WFO ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    # ìµœì¢… ì„±ê³¼ ê³„ì‚°
    if compounded_equity.empty:
        total_return = 0.0
        mdd = 0.0
    else:
        equity_curve = compounded_equity.iloc[:, 0] if isinstance(compounded_equity, pd.DataFrame) else compounded_equity
        if equity_curve.empty or not np.isfinite(equity_curve.iloc[0]) or equity_curve.iloc[0] == 0:
            total_return = 0.0
            mdd = 0.0
        else:
            start_val = equity_curve.iloc[0]
            end_val = equity_curve.iloc[-1]
            total_return = (end_val / start_val - 1) * 100
            rolling_max = equity_curve.cummax()
            drawdown = equity_curve / rolling_max - 1
            mdd = drawdown.min() * 100

    logging.info(f"[ì¢…í•© í¬íŠ¸í´ë¦¬ì˜¤] ì´ ìˆ˜ìµë¥ : {total_return:.2f}%, MDD: {mdd:.2f}%")
    
    # ê·¸ë˜í”„ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    results_data = {'Total Portfolio': compounded_equity}
    
    for name, curve in final_strategy_results.items():
        results_data[name] = curve # ê·¸ë˜í”„ìš© ë°ì´í„° ì¶”ê°€
        if curve.empty or curve.iloc[0] == 0:
            ret, mdd_val = 0.0, 0.0
        else:
            ret = (curve.iloc[-1] / curve.iloc[0] - 1) * 100
            rolling_max = curve.cummax()
            drawdown = curve / rolling_max - 1
            mdd_val = drawdown.min() * 100
        
        if pd.isna(ret): ret = 0.0
        if pd.isna(mdd_val): mdd_val = 0.0
        logging.info(f"  [{name}] ì´ ìˆ˜ìµë¥ : {ret:.2f}%, MDD: {mdd_val:.2f}%")

    # ìµœì¢… ê·¸ë˜í”„ ì‹œê°í™”
    plot_wfo_results(results_data, title='Walk-Forward Optimization Results (KR Stocks)')


if __name__ == '__main__':
    # ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œì‘ ë°©ì‹ ì„¤ì • (Windows í˜¸í™˜)
    multiprocessing.set_start_method('spawn', force=True)
    main()
